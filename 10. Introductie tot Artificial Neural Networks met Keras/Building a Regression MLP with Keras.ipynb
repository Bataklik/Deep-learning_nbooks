{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2b09ce",
   "metadata": {},
   "source": [
    "# 7. Building a Regression MLP with Keras\n",
    "\n",
    "## 7.1. De Data: California Housing\n",
    "\n",
    "Voor regressie gebruiken we de **California Housing dataset** om huizenprijzen te voorspellen.\n",
    "\n",
    "- **Kenmerken:** De dataset bevat enkel numerieke features en heeft geen ontbrekende waarden.\n",
    "- **Laden:** We gebruiken `fetch_california_housing` van Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd28d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Splitsen in training+validatie en test set\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "\n",
    "# Splitsen van de training set in train en validatie\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d264c51d",
   "metadata": {},
   "source": [
    "## 7.2. Architectuur en Configuratie\n",
    "\n",
    "Een regressie MLP verschilt op een paar cruciale punten van een classifier:\n",
    "\n",
    "- **Output Neuron:** Omdat we een enkele waarde voorspellen, gebruiken we slechts **één output neuron**.\n",
    "- **Activatie:** De output laag heeft **geen activatiefunctie**.\n",
    "- **Loss Functie:** We gebruiken **Mean Squared Error (MSE)**, wat standaard is voor regressie.\n",
    "- **Optimizer:** In dit voorbeeld gebruiken we de **Adam** optimizer (een variant van SGD) met een learning rate van $10^{-3}$.\n",
    "- **Hidden Layers:** Het model bevat 3 verborgen lagen met elk 50 neuronen en de ReLU-activatiefunctie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1563b5c",
   "metadata": {},
   "source": [
    "## 7.3. Normalisatie met de `Normalization` Laag\n",
    "\n",
    "In plaats van handmatige schaling (zoals `/ 255.` bij afbeeldingen), gebruiken we een Keras `Normalization` laag.\n",
    "\n",
    "- **Functie:** Deze laag doet hetzelfde als de `StandardScaler` van Scikit-Learn (gemiddelde op 0, variantie op 1 brengen).\n",
    "- **Belangrijk:** Je moet de methode `adapt()` aanroepen op de trainingsdata **voordat** je `fit()` aanroept. De laag berekent dan het gemiddelde en de variantie van elke feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee1c04",
   "metadata": {},
   "source": [
    "## 4. Implementatie in Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2d45fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - RootMeanSquaredError: 0.9522 - loss: 0.9066 - val_RootMeanSquaredError: 0.7028 - val_loss: 0.4939\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - RootMeanSquaredError: 0.6118 - loss: 0.3743 - val_RootMeanSquaredError: 0.7640 - val_loss: 0.5836\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - RootMeanSquaredError: 0.5936 - loss: 0.3524 - val_RootMeanSquaredError: 0.5791 - val_loss: 0.3354\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - RootMeanSquaredError: 0.5787 - loss: 0.3349 - val_RootMeanSquaredError: 0.5815 - val_loss: 0.3382\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - RootMeanSquaredError: 0.5741 - loss: 0.3295 - val_RootMeanSquaredError: 0.8223 - val_loss: 0.6761\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - RootMeanSquaredError: 0.5636 - loss: 0.3176 - val_RootMeanSquaredError: 0.5372 - val_loss: 0.2886\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - RootMeanSquaredError: 0.5511 - loss: 0.3038 - val_RootMeanSquaredError: 1.3944 - val_loss: 1.9444\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - RootMeanSquaredError: 0.5629 - loss: 0.3169 - val_RootMeanSquaredError: 0.7626 - val_loss: 0.5816\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - RootMeanSquaredError: 0.5419 - loss: 0.2936 - val_RootMeanSquaredError: 0.9547 - val_loss: 0.9115\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - RootMeanSquaredError: 0.5462 - loss: 0.2984 - val_RootMeanSquaredError: 1.1254 - val_loss: 1.2666\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - RootMeanSquaredError: 0.5399 - loss: 0.2915 - val_RootMeanSquaredError: 1.3998 - val_loss: 1.9594\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - RootMeanSquaredError: 0.5455 - loss: 0.2975 - val_RootMeanSquaredError: 0.9577 - val_loss: 0.9171\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - RootMeanSquaredError: 0.5378 - loss: 0.2892 - val_RootMeanSquaredError: 0.6530 - val_loss: 0.4263\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - RootMeanSquaredError: 0.5296 - loss: 0.2805 - val_RootMeanSquaredError: 0.5643 - val_loss: 0.3184\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - RootMeanSquaredError: 0.5260 - loss: 0.2767 - val_RootMeanSquaredError: 0.5262 - val_loss: 0.2769\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - RootMeanSquaredError: 0.5242 - loss: 0.2747 - val_RootMeanSquaredError: 0.5680 - val_loss: 0.3226\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - RootMeanSquaredError: 0.5207 - loss: 0.2711 - val_RootMeanSquaredError: 0.5426 - val_loss: 0.2944\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - RootMeanSquaredError: 0.5190 - loss: 0.2693 - val_RootMeanSquaredError: 0.5211 - val_loss: 0.2715\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - RootMeanSquaredError: 0.5203 - loss: 0.2708 - val_RootMeanSquaredError: 0.5183 - val_loss: 0.2686\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - RootMeanSquaredError: 0.5159 - loss: 0.2662 - val_RootMeanSquaredError: 0.6347 - val_loss: 0.4028\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# 1. Normalisatie laag definiëren\n",
    "norm_layer = keras.layers.Normalization()\n",
    "\n",
    "# 2. Model opbouwen\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]),\n",
    "    norm_layer,\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(1) # Geen activatie voor regressie output\n",
    "])\n",
    "\n",
    "# 3. Compileren\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "# 4. Data aanpassen en trainen\n",
    "norm_layer.adapt(X_train) # Bereken mean/variance voor schaling\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30acd3a9",
   "metadata": {},
   "source": [
    "## 5. Evaluatie en Voorspelling\n",
    "\n",
    "Na de training evalueren we de prestaties op de testset en maken we voorspellingen voor nieuwe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28c966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step - RootMeanSquaredError: 0.5342 - loss: 0.2853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluatie op test data\n",
    "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Voorspelling maken\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep-learning_nbooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
